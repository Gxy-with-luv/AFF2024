{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHTu08UC4seL"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Setup dependencies\n",
        "%%bash\n",
        "\n",
        "if [ ! -d params ]; then\n",
        "  mkdir params\n",
        "  curl -fsSL https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar | tar x -C params\n",
        "fi\n",
        "\n",
        "if [ ! -d alphafold ]; then\n",
        "  git clone https://github.com/deepmind/alphafold.git\n",
        "  ! pip -q install ml-collections dm-haiku biopython==1.81\n",
        "fi\n",
        "\n",
        "if [ ! -d output ]; then\n",
        "  mkdir output\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyuGtGrG3Zc0",
        "outputId": "3449bab4-cd75-4fc7-a798-47ba70c59fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/Bio/Data/SCOPData.py:18: BiopythonDeprecationWarning: The 'Bio.Data.SCOPData' module will be deprecated in a future release of Biopython in favor of 'Bio.Data.PDBData.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## Define functions to run AlphaFold\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import hashlib\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import re\n",
        "import subprocess\n",
        "from glob import glob\n",
        "\n",
        "sys.path.append('alphafold')\n",
        "\n",
        "from alphafold.model import model, config, data\n",
        "from alphafold.data import parsers, pipeline\n",
        "from alphafold.common import protein\n",
        "\n",
        "\"\"\"\n",
        "Create an AlphaFold model runner\n",
        "name -- The name of the model to get the parameters from. Options: model_[1-5]\n",
        "\"\"\"\n",
        "\n",
        "def make_model_runner(model_num=3, recycles=1, deterministic=True):\n",
        "  model_name = 'model_%d_ptm' % model_num\n",
        "  cfg = config.model_config(model_name)\n",
        "\n",
        "  cfg.data.common.num_recycle = recycles\n",
        "  cfg.model.num_recycle = recycles\n",
        "  cfg.data.eval.num_ensemble = 1\n",
        "  if deterministic:\n",
        "    cfg.data.eval.masked_msa_replace_fraction = 0.0\n",
        "    cfg.model.global_config.deterministic = True\n",
        "  params = data.get_model_haiku_params(model_name, '.')\n",
        "\n",
        "  return model.RunModel(cfg, params)\n",
        "\n",
        "def make_processed_feature_dict(runner, a3m_file, name=\"test\", seed=0):\n",
        "  feature_dict = {}\n",
        "\n",
        "  # assumes sequence is first entry in msa\n",
        "  with open(a3m_file,'r') as msa_fil:\n",
        "    sequence = msa_fil.read().splitlines()[1].strip()\n",
        "\n",
        "  feature_dict.update(pipeline.make_sequence_features(sequence, name, len(sequence)))\n",
        "\n",
        "  with open(a3m_file,'r') as msa_fil:\n",
        "    msa = pipeline.parsers.parse_a3m(msa_fil.read())\n",
        "\n",
        "  feature_dict.update(pipeline.make_msa_features([msa]))\n",
        "  processed_feature_dict = runner.process_features(feature_dict, random_seed=seed)\n",
        "\n",
        "  return processed_feature_dict\n",
        "\n",
        "\"\"\"\n",
        "Package AlphaFold's output into an easy-to-use dictionary\n",
        "prediction_result - output from running AlphaFold on an input dictionary\n",
        "processed_feature_dict -- The dictionary passed to AlphaFold as input. Returned by `make_processed_feature_dict`.\n",
        "\"\"\"\n",
        "def parse_results(prediction_result, processed_feature_dict):\n",
        "  b_factors = prediction_result['plddt'][:,None] * prediction_result['structure_module']['final_atom_mask']\n",
        "  dist_bins = jax.numpy.append(0,prediction_result[\"distogram\"][\"bin_edges\"])\n",
        "  dist_mtx = dist_bins[prediction_result[\"distogram\"][\"logits\"].argmax(-1)]\n",
        "  contact_mtx = jax.nn.softmax(prediction_result[\"distogram\"][\"logits\"])[:,:,dist_bins < 8].sum(-1)\n",
        "\n",
        "  out = {\"unrelaxed_protein\": protein.from_prediction(processed_feature_dict, prediction_result, b_factors=b_factors),\n",
        "        \"plddt\": prediction_result['plddt'],\n",
        "        \"pLDDT\": prediction_result['plddt'].mean(),\n",
        "        \"dists\": dist_mtx,\n",
        "        \"adj\": contact_mtx}\n",
        "\n",
        "  out.update({\"pae\": prediction_result['predicted_aligned_error'],\n",
        "              \"pTMscore\": prediction_result['ptm']})\n",
        "  return out\n",
        "\n",
        "def write_results(result, pdb_out_path):\n",
        "  plddt = float(result['pLDDT'])\n",
        "  ptm = float(result[\"pTMscore\"])\n",
        "  print('plddt: %.3f' % plddt)\n",
        "  print('ptm  : %.3f' % ptm)\n",
        "\n",
        "  pdb_lines = protein.to_pdb(result[\"unrelaxed_protein\"])\n",
        "  with open(pdb_out_path, 'w') as f:\n",
        "    f.write(pdb_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrD9lj4Ub1G_"
      },
      "outputs": [],
      "source": [
        "!pip install mdtraj\n",
        "import mdtraj as md\n",
        "\n",
        "gspdb = md.load_pdb('closeCA.pdb')\n",
        "espdb = md.load_pdb('openCA.pdb')\n",
        "def calpdb(pdb):\n",
        "  pdb = md.load_pdb(pdb)\n",
        "  atoms = pdb.top.select('name CA')\n",
        "  pdb = pdb.atom_slice(atoms)\n",
        "  pdb.superpose(gspdb, 0)\n",
        "  d1 = md.rmsd(pdb, gspdb)\n",
        "  pdb.superpose(espdb, 0)\n",
        "  d2 = md.rmsd(pdb, espdb)\n",
        "  return(d1,d2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3TwAgGe4T-A"
      },
      "outputs": [],
      "source": [
        "n_recycles = 3\n",
        "model_number = 3\n",
        "seed=0\n",
        "name='ordered'\n",
        "\n",
        "\n",
        "runner = make_model_runner(model_num=model_number, recycles=n_recycles)\n",
        "\n",
        "subsampled_msas = glob('subsampled_MSAs/*.a3m')\n",
        "subsampled_msas = sorted(subsampled_msas)\n",
        "print(len(subsampled_msas))\n",
        "count=0\n",
        "\n",
        "for fil in subsampled_msas:\n",
        "  print(fil)\n",
        "  if os.path.exists('./drive/MyDrive/AdK_seq/erase_es_results/'+ os.path.basename(fil).replace('.a3m','.pdb'))== False:\n",
        "    features = make_processed_feature_dict(runner, fil, seed=seed)\n",
        "    result = parse_results(runner.predict(features, random_seed=seed), features)\n",
        "    pae = np.array(result['pae'])\n",
        "    np.save('output/pae_' + os.path.basename(fil).replace('.a3m','_0.npy'), pae)\n",
        "    write_results(result, 'output/' + os.path.basename(fil).replace('.a3m','.pdb'))\n",
        "    print(calpdb('output/' + os.path.basename(fil).replace('.a3m','.pdb')))\n",
        "    count += 1\n",
        "  if count % 10 == 0:\n",
        "    os.system('scp ./output/* ./drive/MyDrive/AdK_seq/erase_es_results')\n",
        "    print('finished count:'+str(count))\n",
        "    #os.system('rm ./output/*')\n",
        "\n",
        "\n",
        "\n",
        "os.system('scp ./output/* ./drive/MyDrive/AdK_seq/erase_es_results')\n",
        "print('finished count:'+str(count))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}